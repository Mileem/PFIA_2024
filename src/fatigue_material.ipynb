{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des tests en fatigue des matériaux\n",
    "## Prédiction de la courbe S-N avec un réseau de neurone informé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd       \n",
    "import numpy as np  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, median_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.losses import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 \n",
    "\n",
    "def set_seeds(seed: int = SEED) -> None:\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    tf.experimental.numpy.random.seed(seed)\n",
    "    # When using the CuDNN backend (CUDA), two additional options must be configured.\n",
    "    #os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    \n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "set_global_determinism(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A propos des données de fatigue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Mileem/PFIA_2024/main/data/raw/AAW.csv', delimiter=';', decimal=',', index_col=0, skiprows=[0]) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Conversion au logarithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert Stress and life cycle into logarithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(data=df, x=\"life_log\", y=\"stress_log_mpa\")\n",
    "g.set_axis_labels(\"Fatigue life (cycles) log-scale\", \"Stress Amplitude (MPa) log-scale\", labelpad=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## Préparation des données avant utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(df[['stress_log_mpa']].values, \n",
    "                                                  df['life_log'], test_size=0.2)\n",
    "\n",
    "(x_train, x_val, y_train, y_val) = (tf.convert_to_tensor(x_train, dtype=tf.float32),tf.convert_to_tensor(x_val, dtype=tf.float32), \n",
    " tf.convert_to_tensor(y_train, dtype=tf.float32), tf.convert_to_tensor(y_val, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des données d'entrainement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(x_train, y_train, x_val, y_val, title):\n",
    "    fig = plt.figure(figsize = (10, 8))\n",
    "    plt.scatter(y_train, x_train, marker='+', label='Train')\n",
    "    plt.scatter(y_val, x_val, marker='+', color='r', label='Val')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Fatigue life (cycles) log-scale')\n",
    "    plt.ylabel('Stress Amplitude (MPa) log-scale')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_dataset(x_train, y_train, x_val, y_val, 'Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un nouveau jeu de donnée de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(df['stress_log_mpa'].min(), \n",
    "                                      df['stress_log_mpa'].max()+0.01, 100).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks\n",
    "## Création de l'architecture du réseau de neurone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfkl = tf.keras.layers\n",
    "tfkm = tf.keras.models\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "def nn_architecture(lr,loss_function): \n",
    "    # TODO: Building the neural network architecture\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_fit(model, x_train, y_train, x_val, y_val, epochs):\n",
    "    model.fit(x_train, y_train, validation_data=(x_val, y_val), \n",
    "                        epochs=epochs, verbose=False, shuffle=True, batch_size = 30)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la Loss fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_knowledge():\n",
    "    #TODO: Create knowledge loss function\n",
    "    \n",
    "    return loss_knowledge_\n",
    "\n",
    "def custom_loss(y_true, y_pred, lambda_penalty):\n",
    "    negloglik = #TODO: Add negative log likelihood loss\n",
    "    return negloglik #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #TODO Create custom loss\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return #TODO return Custom loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement du réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(epochs, lr, lambda_penalty, x_collocation) :\n",
    "    loss_fn = #TODO\n",
    "    model = #TODO\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "epochs = #TODO\n",
    "lr = #TODO\n",
    "lambda_penalty = #TODO\n",
    "\n",
    "model = create_model(#TODO)\n",
    "model = model_fit(#TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_test)\n",
    "y_pred_mean = y_pred.mean()\n",
    "y_pred_std = y_pred.stddev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de la Courbe S-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 8))\n",
    "plt.scatter(y_train, x_train, marker='+', label='Train')\n",
    "plt.plot(y_pred_mean, x_test, color='r', label='Predicted Mean')\n",
    "plt.fill_betweenx(x_test.ravel(), np.array(y_pred_mean+1.96*y_pred_std).ravel(), np.array(y_pred_mean-1.96*y_pred_std).ravel(), x_test.ravel(), color='C1', alpha=0.5, label='95% Confidence Level')\n",
    "plt.title(f'PINN on fatigue life cycles, epochs={epochs}, learning rate={lr}, 95% Confidence Level')\n",
    "plt.xlabel('Fatigue life (cycles) log-scale')\n",
    "plt.ylabel('Stress Amplitude (MPa) log-scale')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation des résultats obtenus\n",
    "### Métriques habituelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_val = model.predict(x_val)\n",
    "r2 = explained_variance_score(y_val, predict_val)\n",
    "rmse = mean_squared_error(y_val, predict_val, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_val, predict_val)\n",
    "print('R2: ', r2)\n",
    "print('RMSE: ', rmse)\n",
    "print('MAPE: ', mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métriques liées aux connaissances (contexte) de la fatigue des matériaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_spearman_std(model, x_test):\n",
    "    #TODO\n",
    "    return spearman_std, p_value_std\n",
    "\n",
    "def evaluate_spearman_mean(model, x_test):\n",
    "    #TODO\n",
    "    return spearman_mean, p_value_mean\n",
    "\n",
    "def evaluate_spearman_curve(model, x_test):\n",
    "    #TODO\n",
    "    return spearman_curve, p_value_curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des coefficients de corrélations de Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_dt = np.gradient(x_test[:, 0])\n",
    "dy_dt = np.gradient(y_pred_mean[:, 0])\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(13, 5))\n",
    "fig.suptitle('Summarize of model')\n",
    "ax1.plot(x_test, y_pred_std, color='r', label='Predicted Standard Deviation')\n",
    "ax1.title.set_text('Standard deviation')\n",
    "ax1.set_xlabel('Stress Amplitude (MPa) log-scale')\n",
    "ax1.set_ylabel('Standard Deviation')\n",
    "\n",
    "ax2.plot(x_test, y_pred_mean, color='r', label='Predicted Mean')\n",
    "ax2.scatter(x_train, y_train, marker='+', label='Train')\n",
    "ax2.title.set_text('Mean')\n",
    "ax2.set_xlabel('Stress Amplitude (MPa) log-scale')\n",
    "ax2.set_ylabel('Mean')\n",
    "\n",
    "ax3.plot(x_test, (dy_dt/dx_dt), color='r', label='Predicted Curvature')\n",
    "ax3.title.set_text('Curvature')\n",
    "ax3.set_xlabel('Stress Amplitude (MPa) log-scale')\n",
    "ax3.set_ylabel('Curvature')\n",
    "\n",
    "# Sauvegarder la figure dans un fichier PNG\n",
    "#plt.savefig('img/results.png', format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_mean, p_value_mean = evaluate_spearman_mean(model, x_test)\n",
    "spearman_std, p_value_std = evaluate_spearman_std(model, x_test)\n",
    "spearman_curve, p_value_curve = evaluate_spearman_curve(model, x_test)\n",
    "print({'Spearman Std': spearman_std, 'p_value std': p_value_std, 'Spearman Mean': spearman_mean, 'p_value mean': p_value_mean, 'Spearman Curve': spearman_curve, 'p_value curve': p_value_curve})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation de plusieurs modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    {'epochs': 800, 'lr': 5e-3, 'lambda': 0, 'x_collocation': x_collocation},\n",
    "    {'epochs': 800, 'lr': 5e-3, 'lambda': 100, 'x_collocation': x_collocation},\n",
    "    {'epochs': 800, 'lr': 5e-3, 'lambda': 1000, 'x_collocation': x_collocation},\n",
    "    {'epochs': 1000, 'lr': 5e-3, 'lambda': 0, 'x_collocation': x_collocation},\n",
    "    {'epochs': 1000, 'lr': 5e-3, 'lambda': 1000, 'x_collocation': x_collocation}\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, config in enumerate(model_configs):\n",
    "    model = create_model(#TODO)\n",
    "    model = model_fit(#TODO)\n",
    "\n",
    "    spearman_mean, p_value_mean = evaluate_spearman_mean(model, x_test)\n",
    "    spearman_std, p_value_std = evaluate_spearman_std(model, x_test)\n",
    "    spearman_curve, p_value_curve = evaluate_spearman_curve(model, x_test)\n",
    "    results.append({'Model': f'Model {i+1}', 'Spearman Std': spearman_std, 'p_value std': p_value_std, 'Spearman Mean': spearman_mean, 'p_value mean': p_value_mean, 'Spearman Curve': spearman_curve, 'p_value curve': p_value_curve})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfia_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
